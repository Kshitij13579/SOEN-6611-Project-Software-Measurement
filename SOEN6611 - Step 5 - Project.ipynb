{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ced60b",
   "metadata": {},
   "source": [
    "# SOEN 6611 - Step 5 - Implementation of Measurement Process\n",
    "\n",
    "### Business Goal\n",
    "Improve quality of big data for machine learning model.\n",
    "\n",
    "### Machine Learning Goal\n",
    "The goal of the machine learning model is to predict whether a particular individual is at high/low credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3ef702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad38a47",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "Out dataset is a credit card dataset containing details of individuals like age, income etc. and a target value stating whether the particular individual is at high or low credit risk. The data is coleected in a form of CSV file and is loaded into the memory using the pandas library. \n",
    "\n",
    "#### Assumption\n",
    "We are considering this file as a single dataset split into three time frames T1, T2 and T3.<br>\n",
    "$Nds$ = number of datasets = 1\n",
    "\n",
    "Source: https://www.kaggle.com/datasets/samuelcortinhas/credit-card-classification-clean-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cdfe8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 4000\n",
      "Count: 3000\n",
      "Count: 2828\n"
     ]
    }
   ],
   "source": [
    "#import data into dataframe\n",
    "\n",
    "df = pd.read_csv('data_manipulated.csv')\n",
    "\n",
    "#split data frame into three parts assuming each part is a separate time frame\n",
    "\n",
    "df_t1 = df.iloc[:4000]\n",
    "df_t2 = df.iloc[4000:7000]\n",
    "df_t3 = df.iloc[7000:]\n",
    "\n",
    "print('Count:', df_t1.shape[0])\n",
    "print('Count:', df_t2.shape[0])\n",
    "print('Count:', df_t3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7617d53",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "\n",
    "num_request - number of requests to database. \n",
    "<br>\n",
    "num_successful_request - number of successful requests to database. <br>\n",
    "**It is assumed that dataframe is equivalent to database and each call to dataframe is considered as request. If the call does not return any error then num_successful_requests is incremented.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e4a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_request = 0\n",
    "num_successful_request = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a0651",
   "metadata": {},
   "source": [
    "### Base Measure Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8352d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method : recCount(df_list) : method to calculate total number of records in multiple datasets <br>\n",
    "# Param : df_list : list of multiple dataframes \n",
    "# Return : Integer : returns total number of records in multiple datasets\n",
    "def recCount(df_list):\n",
    "    global num_request\n",
    "    global num_successful_request\n",
    "    num_records = 0\n",
    "    for i in df_list:\n",
    "        num_request += 1\n",
    "        num_records += i.shape[0]\n",
    "        num_successful_request += 1\n",
    "    \n",
    "    return num_records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a50298b",
   "metadata": {},
   "source": [
    "## Big Data Quality Indicators\n",
    "### Veracity\n",
    "\n",
    "Veracity refers to the degree that data is accurate, trusted and precise. It is not only the accuracy of the data itself but the trustworthiness of the data source, type, and processing of it.\n",
    "<br>\n",
    "$Veracity = W_{acc} * Accuracy + W_{comp} * Completeness + W_{curr} * Currentness + W_{avail} * Availability$\n",
    "\n",
    "Derived Measures:\n",
    "- Accuracy\n",
    "- Completeness\n",
    "- Currentness\n",
    "- Availability\n",
    "\n",
    "#### Accuracy\n",
    "Degree to which data has attributes that correctly represent the true value of the intended attribute of a concept or event in a specific context of use.\n",
    "<br><br>\n",
    "$H_{acc} = log_2(Lbd) - (1/Lbd) * \\sum{p_j * log_2(p_j)}$ <br>\n",
    "$H_{max} = log_2(Lbd)$ <br>\n",
    "$Accuracy = H_{acc} / H_{max}$ <br>\n",
    "\n",
    "$Lbd$ : number of records in dataset <br>\n",
    "$p_j$ : total number of duplicate records in dataset <br>\n",
    "$H_{acc}$ : entropy of multiple datasets\n",
    "\n",
    "#### Completeness\n",
    "Degree to which subject data associated with an entity has values for all expected attributes and related entity instances in a specific context of use.\n",
    "<br><br>\n",
    "$Com_m(MDS) = \\frac{rec\\_no\\_null(MDS)}{Lbd(MDS)}$\n",
    "\n",
    "$Rec\\_no\\_null (MDS)$ : Frequency of records (in MDS) with no null values<br>\n",
    "$Lbd$ : number of records in dataset <br>\n",
    "\n",
    "#### Currentness\n",
    "Degree to which data has attributes that are of the right age in a specific context of use. \n",
    "<br><br>\n",
    "$Currentness(MDS) = \\frac{rec\\_acc\\_age(MDS)}{Lbd(MDS)}$\n",
    "\n",
    "$Rec\\_acc\\_age(MDS)$ : Provides the total number of records with ages that fall within the acceptable range based on the upper and lower quartiles of the Box and Whisker. <br>\n",
    "$Lbd(MDS)$ : Total Number of records in MDS\n",
    "\n",
    "#### Availability\n",
    "Degree to which data has attributes that enable it to be retrieved by authorized users and/or applications in a specific context of use. \n",
    "<br><br>\n",
    "$Availability(MDS) = \\frac{N\\_succ\\_req (MDS)}{N\\_req (MDS)} $\n",
    "\n",
    "$N\\_succ\\_req (MDS)$ : Number of successful requests (from an API, server, datastore, origins of data, etc) <br>\n",
    "$N\\_req (MDS)$ : Number of requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ee7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "def getAccuracy(df_list):\n",
    "    num_records = recCount(df_list)\n",
    "    global num_request\n",
    "    global num_successful_request\n",
    "    sum=0\n",
    "    for i in df_list:\n",
    "        num_request += 1\n",
    "        if i.duplicated().sum() != 0:\n",
    "            sum += (i.duplicated().sum() * np.log2(i.duplicated().sum()))\n",
    "        num_successful_request += 1\n",
    "    \n",
    "    \n",
    "    Hacc = np.log2(num_records) - (1/num_records) * sum\n",
    "    Hmax = np.log2(num_records)\n",
    "    \n",
    "    return (Hacc / Hmax) \n",
    "\n",
    "#Completeness\n",
    "def getCompleteness(df_list):\n",
    "    num_records = recCount(df_list)\n",
    "    global num_request\n",
    "    global num_successful_request\n",
    "    rec_null=0\n",
    "    for i in df_list:\n",
    "        num_request += 1\n",
    "        rec_null += i.isnull().any(axis=1).sum()\n",
    "        num_successful_request += 1\n",
    "    \n",
    "    return ((num_records - rec_null) / num_records)\n",
    "    \n",
    "\n",
    "#Currentness\n",
    "def getCurrentness(df_list):\n",
    "    num_records = recCount(df_list)\n",
    "    \n",
    "    #converting string date to pandas Date type\n",
    "    combine_df = pd.concat([df_t1,df_t2,df_t3])\n",
    "    combine_df = combine_df.dropna(subset=['Date'])\n",
    "    combine_df['Date'] = pd.to_datetime(combine_df['Date'], format='%m/%d/%Y')\n",
    "    combine_df = combine_df.sort_values(by='Date')\n",
    "    \n",
    "    #performing box and whisker analysis on Date column\n",
    "    n = combine_df.shape[0]\n",
    "    lower = np.ceil((n+1)/4).astype('int64')-1\n",
    "    higher = np.ceil((3/4) *(n+1)).astype('int64')-1\n",
    "    date_lower = combine_df.iloc[lower]['Date']\n",
    "    date_higher = combine_df.iloc[higher]['Date']\n",
    "    count = combine_df.loc[combine_df['Date'].between(date_lower,date_higher,inclusive='both')].shape[0]\n",
    "    \n",
    "    return count / num_records\n",
    "\n",
    "#Availability\n",
    "def getAvailability():\n",
    "    return num_successful_request / num_request\n",
    "\n",
    "#Veracity\n",
    "def getVeracity(df_list, w_acc=1/4, w_comp=1/4, w_curr=1/4 ,w_avail = 1/4):\n",
    "    \n",
    "    if((w_acc + w_comp + w_curr + w_avail) > 1):\n",
    "        print(\"Sum of weights is greater than one\")\n",
    "        return\n",
    "    \n",
    "    return (w_acc * getAccuracy(df_list)) + (w_comp * getCompleteness(df_list)) + (w_curr * getCurrentness(df_list)) + (w_avail * getAvailability())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f4e90",
   "metadata": {},
   "source": [
    "### Vincularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c6a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d05ca102",
   "metadata": {},
   "source": [
    "### Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e1abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd49c01",
   "metadata": {},
   "source": [
    "### Measuring Indicators before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4aa02fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997080550774292\n",
      "Completeness: 0.9930809930809931\n",
      "Currentness: 0.4994912494912495\n",
      "Availability: 1.0\n",
      "Veracity: 0.8730700744124179\n"
     ]
    }
   ],
   "source": [
    "#Veracity\n",
    "accuracy = getAccuracy([df_t1,df_t2,df_t3])\n",
    "completeness = getCompleteness([df_t1,df_t2,df_t3])\n",
    "currentness = getCurrentness([df_t1,df_t2,df_t3])\n",
    "availability = getAvailability()\n",
    "veracity = getVeracity([df_t1,df_t2,df_t3])\n",
    "\n",
    "print('Accuracy:',accuracy)\n",
    "print('Completeness:',completeness)\n",
    "print('Currentness:',currentness)\n",
    "print('Availability:',availability)\n",
    "print('Veracity:',veracity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vincularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9265a",
   "metadata": {},
   "source": [
    "### Analyzing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc60bfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "Gender             16\n",
       "Own_car            16\n",
       "Own_property       16\n",
       "Work_phone         44\n",
       "Phone              20\n",
       "Email              16\n",
       "Unemployed         16\n",
       "Num_children       16\n",
       "Num_family         44\n",
       "Account_length     16\n",
       "Total_income       16\n",
       "Age                16\n",
       "Years_employed     16\n",
       "Income_type        16\n",
       "Education_type     16\n",
       "Family_status      16\n",
       "Housing_type       16\n",
       "Occupation_type    16\n",
       "Target             16\n",
       "Date               16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5db374",
   "metadata": {},
   "source": [
    "There are null values in all the columns except ID and these rows with null values needs to be removed as part of cleaning the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe85bed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking duplicate records\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f95a82",
   "metadata": {},
   "source": [
    "There are 11 duplicate rows which needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0f6772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Numeric Values Gender: 0\n",
      "Non Numeric Values Car: 0\n",
      "Non Numeric Values Property: 0\n",
      "Non Numeric Values Work Phone: 0\n",
      "Non Numeric Values Phone: 32\n",
      "Non Numeric Values Email: 0\n",
      "Non Numeric Values Unemployed: 56\n",
      "Non Numeric Values Target: 52\n"
     ]
    }
   ],
   "source": [
    "# checking for gender, own_car, own_property, work_phone, phone, email, unemployed and Target columns not having values 1 or 0\n",
    "count_gender = (~df['Gender'].isna() & ~df['Gender'].isin([1,0])).sum()\n",
    "count_car = (~df['Own_car'].isna() & ~df['Own_car'].isin([1,0])).sum()\n",
    "count_property = (~df['Own_property'].isna() & ~df['Own_property'].isin([1,0])).sum()\n",
    "count_work_phone = (~df['Work_phone'].isna() & ~df['Work_phone'].isin([1,0])).sum()\n",
    "count_phone = (~df['Phone'].isna() & ~df['Phone'].isin([1,0])).sum()\n",
    "count_email = (~df['Email'].isna() & ~df['Email'].isin([1,0])).sum()\n",
    "count_unemployed = (~df['Unemployed'].isna() & ~df['Unemployed'].isin(['1','0'])).sum()\n",
    "count_target = (~df['Target'].isna() & ~df['Target'].isin([1,0])).sum()\n",
    "\n",
    "print('Non Numeric Values Gender:', count_gender)\n",
    "print('Non Numeric Values Car:', count_car)\n",
    "print('Non Numeric Values Property:', count_property)\n",
    "print('Non Numeric Values Work Phone:', count_work_phone)\n",
    "print('Non Numeric Values Phone:', count_phone)\n",
    "print('Non Numeric Values Email:', count_email)\n",
    "print('Non Numeric Values Unemployed:', count_unemployed)\n",
    "print('Non Numeric Values Target:', count_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e672d1a8",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbab4efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 3966\n",
      "Count: 2966\n",
      "Count: 2828\n"
     ]
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    #remove rows with atleast 1 null value\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Function call\n",
    "df_t1_processed = preprocess(df_t1)\n",
    "df_t2_processed = preprocess(df_t2)\n",
    "df_t3_processed = preprocess(df_t3)\n",
    "\n",
    "print('Count:', df_t1_processed.shape[0])\n",
    "print('Count:', df_t2_processed.shape[0])\n",
    "print('Count:', df_t3_processed.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332e1ec",
   "metadata": {},
   "source": [
    "### Measuring Indicators after processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35cbfe",
   "metadata": {},
   "source": [
    "### Visualizing and Interpreting Indicators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
